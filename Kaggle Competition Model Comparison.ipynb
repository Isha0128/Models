{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "SRr2YLp4aaQH",
        "outputId": "961154ad-7c38-4efc-a354-88f798ae02ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-323c36b6-72cf-452b-b508-ccc8032b6c0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-323c36b6-72cf-452b-b508-ccc8032b6c0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving sample_submission.parquet to sample_submission.parquet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "IG5fegyCarqc",
        "outputId": "f65864d4-8b14-462f-9c81-9f359e2406b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94752fe2-0ecb-4f95-b389-35a37a4c3f96\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94752fe2-0ecb-4f95-b389-35a37a4c3f96\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving train.parquet to train.parquet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LFZvkaMdbho-",
        "outputId": "982aec2c-b52d-4090-abc8-5ff3c66ae52f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edc4d608-bc66-447e-96f1-171b0d286eaf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edc4d608-bc66-447e-96f1-171b0d286eaf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving test.parquet to test.parquet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvpe4ihTZwP0",
        "outputId": "4cf29813-832f-4444-9285-bf0cf0eb2527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes:\n",
            "Classical: (1639424, 9) (409856, 9)\n",
            "Deep Learning: (1639424, 9) (409856, 9)\n",
            "Target: (1639424,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def preprocess_data(train, test):\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    y = train['target']\n",
        "    X_train = train.drop(columns=['target']).copy()\n",
        "    X_test = test.copy()\n",
        "\n",
        "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = X_train.select_dtypes(exclude=[np.number, 'datetime']).columns.tolist()\n",
        "    date_cols = X_train.select_dtypes(include=['datetime']).columns.tolist()\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        median_val = X_train[col].median()\n",
        "        X_train[col] = X_train[col].fillna(median_val)\n",
        "        X_test[col] = X_test[col].fillna(median_val)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        mode_val = X_train[col].mode()[0]\n",
        "        X_train[col] = X_train[col].fillna(mode_val)\n",
        "        X_test[col] = X_test[col].fillna(mode_val)\n",
        "\n",
        "    for col in date_cols:\n",
        "        for df in [X_train, X_test]:\n",
        "            df[col + '_year'] = df[col].dt.year\n",
        "            df[col + '_month'] = df[col].dt.month\n",
        "            df[col + '_day'] = df[col].dt.day\n",
        "            df[col + '_weekday'] = df[col].dt.weekday\n",
        "        X_train.drop(columns=[col], inplace=True)\n",
        "        X_test.drop(columns=[col], inplace=True)\n",
        "\n",
        "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    X_train_classical = X_train.copy()\n",
        "    X_test_classical = X_test.copy()\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        X_train_classical[col] = le.fit_transform(X_train_classical[col].astype(str))\n",
        "        X_test_classical[col] = X_test_classical[col].map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)\n",
        "\n",
        "    X_test_classical = X_test_classical.reindex(columns=X_train_classical.columns, fill_value=0)\n",
        "\n",
        "    X_train_dl = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
        "    X_test_dl = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
        "    X_test_dl = X_test_dl.reindex(columns=X_train_dl.columns, fill_value=0)\n",
        "\n",
        "    return X_train_classical, X_test_classical, X_train_dl, X_test_dl, y\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_parquet('train.parquet')\n",
        "sample = pd.read_parquet('sample_submission.parquet')\n",
        "test = pd.read_parquet('test.parquet')\n",
        "\n",
        "X_train_classical, X_test_classical, X_train_dl, X_test_dl, y = preprocess_data(train, test)\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"Classical:\", X_train_classical.shape, X_test_classical.shape)\n",
        "print(\"Deep Learning:\", X_train_dl.shape, X_test_dl.shape)\n",
        "print(\"Target:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezllGavLcDXs",
        "outputId": "14f1fb40-6518-4e1a-a351-49e5e45b6b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classical ML Data Shape: (1639424, 9) (409856, 9)\n",
            "Deep Learning Data Shape: (1639424, 9) (409856, 9)\n"
          ]
        }
      ],
      "source": [
        "X_train_classical, X_test_classical, X_train_dl, X_test_dl, y = preprocess_data(train, test)\n",
        "\n",
        "print(\"Classical ML Data Shape:\", X_train_classical.shape, X_test_classical.shape)\n",
        "print(\"Deep Learning Data Shape:\", X_train_dl.shape, X_test_dl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOQ6vNDcIO_",
        "outputId": "457ad7d7-a0a2-4ee9-c928-ef1c93a373b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1] int64\n"
          ]
        }
      ],
      "source": [
        "y = y.astype(int)\n",
        "print(y.unique(), y.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT1NeptmcYm7",
        "outputId": "f153e1af-c4b3-41a0-d7a5-2de2cdef0cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classical ML shapes:\n",
            "Train: (1311539, 9) Validation: (327885, 9)\n",
            "\n",
            "Deep Learning shapes:\n",
            "Train: (1311539, 9) Validation: (327885, 9)\n",
            "\n",
            "Target shapes:\n",
            "y_train: (1311539,) y_val: (327885,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr_class, X_val_class, y_tr, y_val = train_test_split(\n",
        "    X_train_classical, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_tr_dl, X_val_dl, _, _ = train_test_split(\n",
        "    X_train_dl, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Classical ML shapes:\")\n",
        "print(\"Train:\", X_tr_class.shape, \"Validation:\", X_val_class.shape)\n",
        "\n",
        "print(\"\\nDeep Learning shapes:\")\n",
        "print(\"Train:\", X_tr_dl.shape, \"Validation:\", X_val_dl.shape)\n",
        "\n",
        "print(\"\\nTarget shapes:\")\n",
        "print(\"y_train:\", y_tr.shape, \"y_val:\", y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ce7vbscdbn",
        "outputId": "3ffeec02-328f-4cfb-c79a-212813c49492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X5              0.097707\n",
            "X1              0.096114\n",
            "X4              0.043767\n",
            "X3              0.018893\n",
            "Date_month      0.002580\n",
            "Date_day       -0.002035\n",
            "Date_weekday   -0.008026\n",
            "Date_year      -0.033194\n",
            "X2             -0.162628\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "corrs = pd.DataFrame(X_tr_class, columns=X_train_classical.columns).corrwith(y_tr)\n",
        "print(corrs.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwW2y2qzch8n",
        "outputId": "9689c699-9ac6-4aaf-a4d2-3291f408db94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target\n",
            "0    0.991437\n",
            "1    0.008563\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(y.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "680zd3dUcob2",
        "outputId": "b9608acc-e914-4789-b284-c81f3c94586b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1311539 327885\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "print(len(X_tr_class), len(X_val_class))\n",
        "print(set(X_tr_class.index).intersection(set(X_val_class.index)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAVccd9dd4hJ",
        "outputId": "7f52532f-1c82-478e-9210-d3588e3d564c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC: 0.5\n",
            "\n",
            "Confusion Matrix:\n",
            " [[325077      0]\n",
            " [  2808      0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9914    1.0000    0.9957    325077\n",
            "           1     0.0000    0.0000    0.0000      2808\n",
            "\n",
            "    accuracy                         0.9914    327885\n",
            "   macro avg     0.4957    0.5000    0.4978    327885\n",
            "weighted avg     0.9829    0.9914    0.9872    327885\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL: .\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
        "clf.fit(X_tr_class, y_tr)\n",
        "\n",
        "y_val_probs = clf.predict_proba(X_val_class)[:, 1]\n",
        "y_val_preds = clf.predict(X_val_class)\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_probs))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_val_preds))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itLKdykmeaGv",
        "outputId": "8d18a55a-114a-450d-82db-bb620d48a82d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 0.5\n",
            "Best F1-score: 0.016982501690971482\n",
            "\n",
            "Confusion Matrix at best threshold:\n",
            " [[     0 325077]\n",
            " [     0   2808]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000    325077\n",
            "           1     0.0086    1.0000    0.0170      2808\n",
            "\n",
            "    accuracy                         0.0086    327885\n",
            "   macro avg     0.0043    0.5000    0.0085    327885\n",
            "weighted avg     0.0001    0.0086    0.0001    327885\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_probs)\n",
        "f1_scores = 2*prec*rec / (prec+rec + 1e-6)  # avoid div by zero\n",
        "\n",
        "best_idx = f1_scores.argmax()\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_thresh)\n",
        "print(\"Best F1-score:\", f1_scores[best_idx])\n",
        "\n",
        "y_val_preds_best = (y_val_probs >= best_thresh).astype(int)\n",
        "\n",
        "print(\"\\nConfusion Matrix at best threshold:\\n\", confusion_matrix(y_val, y_val_preds_best))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds_best, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woAzK9xLenn4",
        "outputId": "a8d34587-6202-44f7-c566-009e438844fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC: 0.9847599272929656\n",
            "\n",
            "Confusion Matrix:\n",
            " [[324927    150]\n",
            " [   902   1906]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9972    0.9995    0.9984    325077\n",
            "           1     0.9270    0.6788    0.7837      2808\n",
            "\n",
            "    accuracy                         0.9968    327885\n",
            "   macro avg     0.9621    0.8392    0.8911    327885\n",
            "weighted avg     0.9966    0.9968    0.9965    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_tr_class, y_tr)\n",
        "\n",
        "y_val_probs = rf.predict_proba(X_val_class)[:, 1]\n",
        "y_val_preds = rf.predict(X_val_class)\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_probs))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_val_preds))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd2qJvBGgeXS",
        "outputId": "d288b434-8b9e-480d-e1c3-25778bbe477e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scale_pos_weight: 115.78886910062333\n",
            "ROC-AUC: 0.992660324299059\n",
            "\n",
            "Confusion Matrix:\n",
            " [[315161   9916]\n",
            " [   164   2644]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9995    0.9695    0.9843    325077\n",
            "           1     0.2105    0.9416    0.3441      2808\n",
            "\n",
            "    accuracy                         0.9693    327885\n",
            "   macro avg     0.6050    0.9555    0.6642    327885\n",
            "weighted avg     0.9927    0.9693    0.9788    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "scale_pos_weight = (y_tr == 0).sum() / (y_tr == 1).sum()\n",
        "print(\"scale_pos_weight:\", scale_pos_weight)\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective=\"binary:logistic\",\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    eval_metric=\"auc\"\n",
        ")\n",
        "\n",
        "xgb.fit(X_tr_class, y_tr)\n",
        "\n",
        "y_val_probs = xgb.predict_proba(X_val_class)[:, 1]\n",
        "y_val_preds = (y_val_probs >= 0.5).astype(int)\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_probs))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_val_preds))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18xhtyupkhfq",
        "outputId": "4f30e844-ce96-43b3-dac9-c5ccbbb4c696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC: 0.8417468533446825\n",
            "Best threshold: 1.0\n",
            "Best F1-score: 0.7132271211554845\n",
            "\n",
            "Confusion Matrix at best threshold:\n",
            " [[324412    665]\n",
            " [   883   1925]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9973    0.9980    0.9976    325077\n",
            "           1     0.7432    0.6855    0.7132      2808\n",
            "\n",
            "    accuracy                         0.9953    327885\n",
            "   macro avg     0.8703    0.8417    0.8554    327885\n",
            "weighted avg     0.9951    0.9953    0.9952    327885\n",
            "\n",
            "Best threshold: 1.0\n",
            "Best F1-score: 0.7132266219718205\n",
            "\n",
            "Confusion Matrix at best threshold:\n",
            " [[324412    665]\n",
            " [   883   1925]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9973    0.9980    0.9976    325077\n",
            "           1     0.7432    0.6855    0.7132      2808\n",
            "\n",
            "    accuracy                         0.9953    327885\n",
            "   macro avg     0.8703    0.8417    0.8554    327885\n",
            "weighted avg     0.9951    0.9953    0.9952    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, classification_report,\n",
        "    confusion_matrix, precision_recall_curve\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "dt = DecisionTreeClassifier(\n",
        "    class_weight=\"balanced\",\n",
        "    max_depth=None,\n",
        "    random_state=42\n",
        ")\n",
        "dt.fit(X_tr_class, y_tr)\n",
        "\n",
        "y_val_probs = dt.predict_proba(X_val_class)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_val_probs)\n",
        "print(\"ROC-AUC:\", roc_auc)\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_probs)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-12)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "best_thresh = thresh[best_idx] if best_idx < len(thresh) else 1.0\n",
        "print(\"Best threshold:\", best_thresh)\n",
        "print(\"Best F1-score:\", f1_scores[best_idx])\n",
        "\n",
        "y_val_pred = (y_val_probs >= best_thresh).astype(int)\n",
        "print(\"\\nConfusion Matrix at best threshold:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_probs)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-6)\n",
        "\n",
        "best_idx = f1_scores.argmax()\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_thresh)\n",
        "print(\"Best F1-score:\", f1_scores[best_idx])\n",
        "\n",
        "y_val_preds_best = (y_val_probs >= best_thresh).astype(int)\n",
        "\n",
        "print(\"\\nConfusion Matrix at best threshold:\\n\", confusion_matrix(y_val, y_val_preds_best))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds_best, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxePbegIhF9C",
        "outputId": "bdbf844c-ec55-476b-efc0-4f26ed4417b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 1.0\n",
            "Best F1-score: 0.7132266219718205\n",
            "\n",
            "Confusion Matrix at best threshold:\n",
            " [[324412    665]\n",
            " [   883   1925]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9973    0.9980    0.9976    325077\n",
            "           1     0.7432    0.6855    0.7132      2808\n",
            "\n",
            "    accuracy                         0.9953    327885\n",
            "   macro avg     0.8703    0.8417    0.8554    327885\n",
            "weighted avg     0.9951    0.9953    0.9952    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_probs)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-6)\n",
        "\n",
        "best_idx = f1_scores.argmax()\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_thresh)\n",
        "print(\"Best F1-score:\", f1_scores[best_idx])\n",
        "\n",
        "# Apply best threshold\n",
        "y_val_preds_best = (y_val_probs >= best_thresh).astype(int)\n",
        "\n",
        "print(\"\\nConfusion Matrix at best threshold:\\n\", confusion_matrix(y_val, y_val_preds_best))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_preds_best, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxs_2Ik5olSm",
        "outputId": "44ba0700-d63f-4e8e-dd13-063b2b2c9940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Comparison:\n",
            "\n",
            "                     ROC-AUC  PR-AUC  Accuracy  Precision  Recall  F1-Score\n",
            "Logistic Regression   0.5000  0.5043    0.9914     0.0000  0.0000    0.0000\n",
            "Random Forest         0.9848  0.8747    0.9968     0.9270  0.6788    0.7837\n",
            "XGBoost               0.9927  0.8091    0.9693     0.2105  0.9416    0.3441\n",
            "Decision Tree         0.8417  0.7156    0.9953     0.7427  0.6855    0.7130\n"
          ]
        }
      ],
      "source": [
        "# --- Logistic Regression ---\n",
        "lr_probs = clf.predict_proba(X_val_class)[:, 1]\n",
        "lr_preds = clf.predict(X_val_class)\n",
        "\n",
        "# --- Random Forest ---\n",
        "rf_probs = rf.predict_proba(X_val_class)[:, 1]\n",
        "rf_preds = rf.predict(X_val_class)\n",
        "\n",
        "# --- XGBoost ---\n",
        "xgb_probs = xgb.predict_proba(X_val_class)[:, 1]\n",
        "xgb_preds = (xgb_probs >= 0.5).astype(int)\n",
        "\n",
        "# --- Decision Tree ---\n",
        "dt_probs = dt.predict_proba(X_val_class)[:, 1]\n",
        "dt_preds = (dt_probs >= 0.5).astype(int)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, precision_recall_curve, auc\n",
        ")\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Helper function to evaluate models\n",
        "def evaluate_model(name, y_true, y_probs, y_preds):\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_probs)\n",
        "    pr_auc = auc(rec, prec)\n",
        "\n",
        "    results[name] = {\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, y_probs),\n",
        "        \"PR-AUC\": pr_auc,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_preds),\n",
        "        \"Precision\": precision_score(y_true, y_preds, zero_division=0),\n",
        "        \"Recall\": recall_score(y_true, y_preds, zero_division=0),\n",
        "        \"F1-Score\": f1_score(y_true, y_preds, zero_division=0),\n",
        "    }\n",
        "\n",
        "# Evaluate all models\n",
        "evaluate_model(\"Logistic Regression\", y_val, lr_probs, lr_preds)\n",
        "evaluate_model(\"Random Forest\", y_val, rf_probs, rf_preds)\n",
        "evaluate_model(\"XGBoost\", y_val, xgb_probs, xgb_preds)\n",
        "evaluate_model(\"Decision Tree\", y_val, dt_probs, dt_preds)\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "df_results = pd.DataFrame(results).T\n",
        "print(\"\\nModel Comparison:\\n\")\n",
        "print(df_results.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3IbSarIx2rOE",
        "outputId": "9edd448b-40ce-4f59-ce14-ac553ea6715e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_7035a439-f552-4cce-95c1-81d023bc6f0f\", \"submission.csv\", 3577604)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "rf_final = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "rf_final.fit(X_train_classical, y)\n",
        "\n",
        "test_preds = rf_final.predict(X_test_classical)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test[\"ID\"],\n",
        "    \"target\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgRkZXJ3V98o",
        "outputId": "2084bd93-3ef6-474f-d3c8-f7368224647e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 11230, number of negative: 1300309\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 752\n",
            "[LightGBM] [Info] Number of data points in the train set: 1311539, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.008562 -> initscore=-4.751768\n",
            "[LightGBM] [Info] Start training from score -4.751768\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttraining's binary_error: 0.00435671\ttraining's auc: 0.991758\tvalid_1's binary_error: 0.00451073\tvalid_1's auc: 0.989691\n",
            "[200]\ttraining's binary_error: 0.00406393\ttraining's auc: 0.992893\tvalid_1's binary_error: 0.00441008\tvalid_1's auc: 0.990015\n",
            "Early stopping, best iteration is:\n",
            "[157]\ttraining's binary_error: 0.00419583\ttraining's auc: 0.992743\tvalid_1's binary_error: 0.00442533\tvalid_1's auc: 0.990373\n",
            "Validation Accuracy: 0.9955746679476036\n",
            "Validation F1 Score: 0.6889603429796356\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    325077\n",
            "           1       0.87      0.57      0.69      2808\n",
            "\n",
            "    accuracy                           1.00    327885\n",
            "   macro avg       0.93      0.79      0.84    327885\n",
            "weighted avg       1.00      1.00      1.00    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "train_data = lgb.Dataset(X_tr_class, label=y_tr)\n",
        "val_data = lgb.Dataset(X_val_class, label=y_val, reference=train_data)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"metric\": [\"binary_error\", \"auc\"],\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 31,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"bagging_freq\": 5,\n",
        "    \"seed\": 42\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    valid_sets=[train_data, val_data],\n",
        "    num_boost_round=1000,\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")\n",
        "y_val_pred_proba = lgb_model.predict(X_val_class, num_iteration=lgb_model.best_iteration)\n",
        "y_val_pred = (y_val_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"Validation F1 Score:\", f1_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vS6H4craNN0",
        "outputId": "d2a438a5-9950-4ffa-a1fe-eea71945501b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 0.3411835764073415\n",
            "Best F1-score: 0.7137939237565574\n",
            "\n",
            "Classification Report at best threshold:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9971    0.9983    0.9977    325077\n",
            "           1     0.7700    0.6652    0.7138      2808\n",
            "\n",
            "    accuracy                         0.9954    327885\n",
            "   macro avg     0.8836    0.8318    0.8557    327885\n",
            "weighted avg     0.9952    0.9954    0.9953    327885\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val, y_val_pred_proba)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-6)\n",
        "\n",
        "best_idx = f1_scores.argmax()\n",
        "best_thresh = thresh[best_idx]\n",
        "\n",
        "print(\"Best threshold:\", best_thresh)\n",
        "print(\"Best F1-score:\", f1_scores[best_idx])\n",
        "\n",
        "y_val_pred_best = (y_val_pred_proba >= best_thresh).astype(int)\n",
        "print(\"\\nClassification Report at best threshold:\\n\",\n",
        "      classification_report(y_val, y_val_pred_best, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6nYa7-QabjH",
        "outputId": "c2e6cd81-704a-4df4-9101-d6ebbb119911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 11230, number of negative: 1300309\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 752\n",
            "[LightGBM] [Info] Number of data points in the train set: 1311539, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.008562 -> initscore=-4.751768\n",
            "[LightGBM] [Info] Start training from score -4.751768\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttraining's binary_error: 0.00435671\ttraining's auc: 0.991758\tvalid_1's binary_error: 0.00451073\tvalid_1's auc: 0.989691\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, precision_recall_curve, auc, classification_report\n",
        ")\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Helper function to evaluate models\n",
        "def evaluate_model(name, y_true, y_probs, y_preds):\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_probs)\n",
        "    pr_auc = auc(rec, prec)\n",
        "\n",
        "    results[name] = {\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, y_probs),\n",
        "        \"PR-AUC\": pr_auc,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_preds),\n",
        "        \"Precision\": precision_score(y_true, y_preds, zero_division=0),\n",
        "        \"Recall\": recall_score(y_true, y_preds, zero_division=0),\n",
        "        \"F1-Score\": f1_score(y_true, y_preds, zero_division=0),\n",
        "    }\n",
        "\n",
        "# --- Logistic Regression ---\n",
        "lr_probs = clf.predict_proba(X_val_class)[:, 1]\n",
        "lr_preds = clf.predict(X_val_class)\n",
        "evaluate_model(\"Logistic Regression\", y_val, lr_probs, lr_preds)\n",
        "\n",
        "# --- Random Forest ---\n",
        "rf_probs = rf.predict_proba(X_val_class)[:, 1]\n",
        "rf_preds = rf.predict(X_val_class)\n",
        "evaluate_model(\"Random Forest\", y_val, rf_probs, rf_preds)\n",
        "\n",
        "# --- XGBoost ---\n",
        "xgb_probs = xgb.predict_proba(X_val_class)[:, 1]\n",
        "xgb_preds = (xgb_probs >= 0.5).astype(int)\n",
        "evaluate_model(\"XGBoost\", y_val, xgb_probs, xgb_preds)\n",
        "\n",
        "# --- Decision Tree ---\n",
        "dt_probs = dt.predict_proba(X_val_class)[:, 1]\n",
        "dt_preds = (dt_probs >= 0.5).astype(int)\n",
        "evaluate_model(\"Decision Tree\", y_val, dt_probs, dt_preds)\n",
        "\n",
        "# --- LightGBM (default 0.5) ---\n",
        "train_data = lgb.Dataset(X_tr_class, label=y_tr)\n",
        "val_data = lgb.Dataset(X_val_class, label=y_val, reference=train_data)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"metric\": [\"binary_error\", \"auc\"],\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 31,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"bagging_freq\": 5,\n",
        "    \"seed\": 42\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    valid_sets=[train_data, val_data],\n",
        "    num_boost_round=1000,\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")\n",
        "\n",
        "lgb_probs = lgb_model.predict(X_val_class, num_iteration=lgb_model.best_iteration)\n",
        "lgb_preds = (lgb_probs >= 0.5).astype(int)\n",
        "evaluate_model(\"LightGBM (0.5)\", y_val, lgb_probs, lgb_preds)\n",
        "\n",
        "# --- LightGBM (best F1 threshold) ---\n",
        "prec, rec, thresh = precision_recall_curve(y_val, lgb_probs)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-6)\n",
        "best_idx = f1_scores.argmax()\n",
        "best_thresh = thresh[best_idx]\n",
        "print(\"Best LightGBM threshold:\", best_thresh)\n",
        "\n",
        "lgb_preds_best = (lgb_probs >= best_thresh).astype(int)\n",
        "evaluate_model(\"LightGBM (Best F1)\", y_val, lgb_probs, lgb_preds_best)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results).T\n",
        "print(\"\\nModel Comparison:\\n\")\n",
        "print(df_results.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd6xWQ8daBf8",
        "outputId": "af82c373-e3c3-48fd-fd86-b26dcfe1bf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [200, 500, 1000],\n",
        "    \"max_depth\": [10, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"class_weight\": [\"balanced\", \"balanced_subsample\"]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    rf, param_grid, n_iter=30, cv=5,\n",
        "    scoring=\"f1\", verbose=2, n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "search.fit(X_train_classical, y)\n",
        "best_rf = search.best_estimator_\n",
        "print(\"Best params:\", search.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}